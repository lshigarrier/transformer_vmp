name : pems_base3
model : weights.pt
# load existing weights from ./models/[name]/[model]
load : False
# Training or inference
train : True
seed : 42
gpu_number : ~
# Use wandb
wandb : True

# model

# use transformer or lstm
transfo : True
# nb of multi-head (n), nb of heads per multi-head (h)
dim : [2, 9]
# use embedding layers
embed : False
# embedding dimensions, if embed: we must have emb[-1]%h = 0, else: we must have input_dim%h=0
emb : ~
# classifiers dimensions, we must have emb[-1] = clas[0]
clas : [963,]
# use uncertainty quantification
vmp : False
# residual connection mode for variance computation : identity, independence, taylor
residual : ~

# training

epochs : 300
batch_size : 32
optimizer : adam
learning_rate : 1.e-2
# End factor to multiply the learning rate at the last epoch
end_factor : 1.e-2
l2_reg : 0.
# l2 regularization hyperparameter in ELBO
kl_factor : ~
# gradient clipping
clip : 10
# nb of workers for dataloaders
workers : 4
# tolerance in (0, 1) for avoiding nan in log(), 1/, sqrt()
tol : ~
# initialization factor for variance
var_init : ~

# dataset

dataset : pems
# input dimension
input_dim : 963
# input sequence length
t_in : 144
# output dimension
output_dim : 7
# output sequence length
t_out : ~
